{
 "metadata": {
  "name": "",
  "signature": "sha256:ef0e6b39a9babeb57180be6a1eec025435e81004f81931bb5e13d5254caff7ed"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import numpy\n",
      "import pandas\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy.stats\n",
      "from scipy.stats import spearmanr\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Impact of Positive/Negative Value on Ranking\n",
      "Here we will generate a set of 101 unthresholded images, add varied amounts of noise to simulate different levels of correlated images, and calculate correlations and rankings for:\n",
      "\n",
      "- unthresholded vs unthresholded (positive and negative in both)\n",
      "- unthresholded vs positive\n",
      "- unthresholded vs negative\n",
      "\n",
      "It is not fair to compare between 1 and the other 2, because in generating 2 and 3 we add zeros (like single imputation). But this will (I think) answer Chris question if we do better with positive or negative. This likely should be tweaked, please give feedback!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nruns=1000\n",
      "\n",
      "# We are interested in impact of including positive/negative values on image rankings (classification)\n",
      "# This will be using single value imputation (0) since that is easiest\n",
      "# (and still comparable with pairwise deletion)\n",
      "\n",
      "# Images will be initialized to have some small correlation\n",
      "\n",
      "# positive and negative, just positive, just negative\n",
      "accuracies = numpy.zeros((nruns,3)) \n",
      "\n",
      "for run in range(nruns):\n",
      "    \n",
      "    # 5 Images, with labels, each correlated to some degree\n",
      "    image1 = numpy.random.randn(100)*1.0\n",
      "    posneg = pandas.DataFrame(image1).transpose()\n",
      "    # Generate levels of correlated images by adding degrees of noise\n",
      "    noise = [x*0.01 for x in range(0,100)]\n",
      "    for x in range(2,len(noise)+2):\n",
      "      posneg.loc[x] = image1 + numpy.random.randn(100)*noise[x-2]    \n",
      "    # Generate positive and negative versions of data\n",
      "    pos = posneg.copy()\n",
      "    pos[pos<0] = 0\n",
      "    neg = posneg.copy()\n",
      "    neg[neg>0] = 0\n",
      "    # We will need number of images before we append set to compare\n",
      "    num_images = pos.shape[0]\n",
      "    # We will compare unthresholded (posneg) against each of positive, negative\n",
      "    pos = pos.append(posneg).transpose()\n",
      "    neg = neg.append(posneg).transpose()\n",
      "    both = posneg.append(posneg).transpose()\n",
      "    # Add column names, for version 1 and 2 of contrast\n",
      "    pos.columns = [\"contrast%s_v1\" %x for x in range(1,num_images+1)] + [\"contrast%s_v2\" %x for x in range(1,num_images+1)]\n",
      "    neg.columns = [\"contrast%s_v1\" %x for x in range(1,num_images+1)] + [\"contrast%s_v2\" %x for x in range(1,num_images+1)]\n",
      "    both.columns = [\"contrast%s_v1\" %x for x in range(1,num_images+1)] + [\"contrast%s_v2\" %x for x in range(1,num_images+1)]\n",
      "    # Calculate correlations\n",
      "    corrs_pos = pos.corr().abs()\n",
      "    corrs_neg = neg.corr().abs()\n",
      "    corrs_both = both.corr().abs()\n",
      "    pos_ranking = [ corrs_pos.sort(columns=x,ascending=False).index.tolist() for x in corrs_pos.columns]\n",
      "    neg_ranking = [ corrs_neg.sort(columns=x,ascending=False).index.tolist() for x in corrs_neg.columns]\n",
      "    both_ranking = [ corrs_both.sort(columns=x,ascending=False).index.tolist() for x in corrs_both.columns]\n",
      "    # Actual labels always order of images (remove version \"v*\" id)\n",
      "    actual = [\"contrast%s\" %x for x in range(1,num_images+1)]\n",
      "    # Create vector of \"True/False\" for each image if its version 2 was the most similar\n",
      "    # This means the second of each list, ranking[x][1] should have the same label (contrastN)\n",
      "    # We also only want to go half way so we don't double count (num_images)\n",
      "    correct_neg = [ re.sub(\"_v[1|2]\",\"\",pos_ranking[x][1]) == actual[x] for x in range(0,num_images)] \n",
      "    correct_pos = [ re.sub(\"_v[1|2]\",\"\",neg_ranking[x][1]) == actual[x] for x in range(0,num_images)] \n",
      "    correct_both = [ re.sub(\"_v[1|2]\",\"\",both_ranking[x][1]) == actual[x] for x in range(0,num_images)] \n",
      "    # Calculate accuracy as sum of Trues / length\n",
      "    accuracies[run,:] = [numpy.sum(correct_both)/(1.0*len(correct_both)),\n",
      "                         numpy.sum(correct_pos)/(1.0*len(correct_pos)),\n",
      "                         numpy.sum(correct_neg)/(1.0*len(correct_neg))]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "acc_df = pandas.DataFrame(accuracies)\n",
      "acc_df.columns = [\"positive and negative\",\"positive\",\"negative\"]\n",
      "print \"Accuracy of Ranking for Unthresholded Maps vs...\"\n",
      "acc_df.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of Ranking for Unthresholded Maps vs...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "positive and negative    0.990099\n",
        "positive                 0.457218\n",
        "negative                 0.457089\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- positive and negative suck compared to using both, but it's not a fair comparison because the latter 2 introduce zeros. The correct way to go about this would be to use pairwise deletion, but then we aren't comparing the same number of values, and it's not going to be a quick matrix operation (and likely the simulation will take forever). I'm kind of stuck and need help on how to do this.\n",
      "- positive only vs. negative only does not make a difference. But this simulation is unlike neuroimaging where the activations are saliently different things."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing Threshold Influence on Ranking"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nruns=500\n",
      "\n",
      "# We are interested in impact of including positive/negative values on image rankings (classification)\n",
      "# This will be using single value imputation (0) since that is easiest\n",
      "\n",
      "# Images will be initialized to have some small correlation\n",
      "\n",
      "# Generate data for 101 (images) (each related to first by some degree of noise)\n",
      "# Define group A as unthresholded\n",
      "# Define group B as some level of thresholding\n",
      "\n",
      "# For each pairwise group, A and B\n",
      "#    Subset data to groups A and B\n",
      "#         For each threshold in 0:4\n",
      "#             Define \u201cgold standard\u201d labels as labels from A, the task and contrast\n",
      "#                   For every map in B assign it a label (task and contrast) corresponding to the most similar in A\n",
      "#                     Calculate (and save) accuracy\n",
      "\n",
      "# positive and negative, just positive, just negative\n",
      "accuracies = numpy.zeros((nruns,3)) \n",
      "\n",
      "# Thresholds \n",
      "thresholds = [0.0,0.5,1.0,1.5,2.0,2.5]\n",
      "\n",
      "for thresh in thresholds:\n",
      "\n",
      "    print thresh\n",
      "    \n",
      "    # We will save 1000 permutations of accuracy for each threshold\n",
      "    accuracies = []\n",
      "    \n",
      "    # Images, with labels, all correlated to some degree\n",
      "    image1 = numpy.random.randn(1000)*1.0\n",
      "    group1 = pandas.DataFrame(image1).transpose()\n",
      "    # Generate levels of correlated images by adding degrees of noise\n",
      "    noise = [x*0.01 for x in range(0,100)]\n",
      "    for x in range(2,len(noise)+2):\n",
      "      # Take N% of random noise added to (1-N) percentage of image 2\n",
      "      group1.loc[x] = (1.0-noise[x-2]*image1) + numpy.random.randn(1000)*noise[x-2]    \n",
      "\n",
      "    # The number of images to make contrast labels later\n",
      "    num_images = group1.shape[0]\n",
      "\n",
      "    for run in range(nruns):\n",
      "        group2 = group1.copy()\n",
      "        # Apply mask, calculate correlation and ranking\n",
      "        column_indices = numpy.where(image1>abs(thresh))[0]\n",
      "        comparison = pandas.DataFrame()\n",
      "        comparison = comparison.append(group1[column_indices])\n",
      "        comparison = comparison.append(group2[column_indices])\n",
      "        comparison = comparison.transpose()\n",
      "        corrs = comparison.corr().abs()\n",
      "        corrs.columns = [\"contrast%s_g1\" %x for x in range(1,num_images+1)] + [\"contrast%s_g2\" %x for x in range(1,num_images+1)]\n",
      "        corrs.index = [\"contrast%s_g1\" %x for x in range(1,num_images+1)] + [\"contrast%s_g2\" %x for x in range(1,num_images+1)]\n",
      "        # We will compare version 1 to version 2, so remove version 1 images from index\n",
      "        version2 = corrs.loc[[\"contrast%s_g2\" %x for x in range(1,num_images+1)],]\n",
      "        rankings = [ version2.sort(columns=x,ascending=False).index.tolist() for x in [\"contrast%s_g1\" %x for x in range(1,num_images+1)]]\n",
      "        # Actual labels always order of images (remove version \"v*\" id)\n",
      "        actual = [\"contrast%s\" %x for x in range(1,num_images+1)]\n",
      "        # Calculate accuracy for each image\n",
      "        correct = [ re.sub(\"_g[1|2]\",\"\",rankings[x][0]) == actual[x] for x in range(0,num_images)] \n",
      "        accuracies.append(numpy.sum(correct)/(len(correct)*1.0))\n",
      "    \n",
      "    print \"Accuracy: %s\" %(numpy.mean(accuracies)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.5\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.0\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.5\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.0\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.5\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.5\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.0\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.5\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.0\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2.5\n",
        "Accuracy: 0.990099009901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n",
        "Accuracy: 0.990099009901"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The accuracy is always very high, meaning that the image in group 2 (with some threshold applied) matched the image in group 1 (without a threshold). My intuition is that there is something wrong in the way I went about this - maybe copying the images and applying the threshold is not the way to go? I'd definitely like some help/feedback to do this correctly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}